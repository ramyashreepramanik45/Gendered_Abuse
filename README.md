# Gendered Abuse Detection for Indic Languages

This repository contains code and instructions for detecting gendered abuse across Indic languages: Hindi, Tamil, and English. It supports three subtasks as defined in the shared task guidelines.

---

## Instructions to run Code

### ðŸ”¹ Subtask 1: Classification using Given Dataset

- Code is located in the `final_codes/TASK1/fusion_hurtlex/` folder.
- Dataset used: **ULI Dataset (label_1 only) and Hurtlex data files**
- Embedding Used: **Glove** for english and **fastext** for tamil,hindi
- Files are available under `uli_dataset-main/training/`,`uli_dataset-main/testing/` and `dataset/Additional_Data/Hurtlex`.

#### Training Files:
- `train_en_l1.csv`
- `train_hi_l1.csv`
- `train_ta_l1.csv`

#### Testing Files:
- `test_en_l1.csv`
- `test_hi_l1.csv`
- `test_ta_l1.csv`

> **Note:** Update file paths in the `.ipynb` notebooks to match the dataset structure before running.

---

### ðŸ”¹ Subtask 2: Transfer Learning with External Data

- Uses **external datasets** + **HurtLex** + **ULI dataset** for fine-tuning.
- Code is located in the `final_codes/TASK2` folder.
####  External Datasets (Located in `Additional_Data/`):

- **MACD Dataset** (Hindi & Tamil):  
  [MACD GitHub Repo â€“ dataset_80_10_10](https://github.com/ShareChatAI/MACD/tree/main/dataset_80_10_10)

- **HASOC Dataset** (English):  
  [HASOC 2019 Dataset](https://hasocfire.github.io/hasoc/2019/dataset.html)


- Embedding Used: **Glove** for english and **fastext** for tamil,hindi

##### Local File Structure:
- `MACD_data/hindi_data/hindi_train.csv`
- `MACD_data/hindi_data/hindi_val.csv`
- `MACD_data/tamil_data/tamil_train.csv`
- `MACD_data/tamil_data/tamil_val.csv`
- `HASOC_data/english_dataset.tsv`
- `HASOC_data/hasoc2019_en_test-2919.tsv`
- `dataset/Additional_Data/Hurtlex/hurtlex_EN.tsv`
- `dataset/Additional_Data/Hurtlex/hurtlex_HI.tsv`

####  Fine-tuning Data (ULI Dataset):
- Use relevant files from `uli_dataset-main/training/` for final training.

>  Modify the paths inside the subtask_2 `.ipynb` notebooks before running.

---

### ðŸ”¹ Subtask 3: Multitask Learning

- Multi-label classification using `label_1` and `label_3` from the **ULI Dataset** and **HurtLex Files**
- Embedding Used: **Glove** for english and **fastext** for tamil,hindi
- Code is located in the `final_codes/TASK3` folder.
#### Files Used:
- **Training:**
  - `train_en_l1.csv`, `train_en_l3.csv`
  - `train_hi_l1.csv`, `train_hi_l3.csv`
  - `train_ta_l1.csv`, `train_ta_l3.csv`
  
- **Testing:**
  - `test_en_l1.csv`, `test_en_l3.csv`
  - `test_hi_l1.csv`, `test_hi_l3.csv`
  - `test_ta_l1.csv`, `test_ta_l3.csv`

>  Ensure to update paths in the `subtask_3/` notebooks to use correct files.

---
### ðŸ”¹ Abuse Lexicon

- **HurtLex** (English):  
  [Hurtlex English](https://github.com/valeriobasile/hurtlex/tree/master/lexica/EN/1.0)

- **HurtLex** (Hindi):  
  [Hurtlex Hindi](https://github.com/valeriobasile/hurtlex/tree/master/lexica/HI/1.0)



##  Directory Structure

```
â”œâ”€â”€ baseline_1
â”‚   â”œâ”€â”€ subtask1
â”‚   â”‚   â”œâ”€â”€ 1_combined.ipynb
â”‚   â”‚   â”œâ”€â”€ 1_english.ipynb
â”‚   â”‚   â”œâ”€â”€ 1_hindi.ipynb
â”‚   â”‚   â””â”€â”€ 1_tamil.ipynb
â”‚   â”œâ”€â”€ subtask2
â”‚   â”‚   â”œâ”€â”€ combined_2.ipynb
â”‚   â”‚   â”œâ”€â”€ eng_2.ipynb
â”‚   â”‚   â”œâ”€â”€ hindi_2.ipynb
â”‚   â”‚   â””â”€â”€ tamil_2.ipynb
â”‚   â””â”€â”€ subtask3
â”‚       â”œâ”€â”€ Combined_subtask3.ipynb
â”‚       â”œâ”€â”€ English_subtask3.ipynb
â”‚       â”œâ”€â”€ Hindi_subtask3.ipynb
â”‚       â””â”€â”€ Tamil_subtask3.ipynb
â”œâ”€â”€ Baseline2
â”‚   â”œâ”€â”€ TASK1
â”‚   â”‚   â”œâ”€â”€ task1-english-base2.ipynb
â”‚   â”‚   â”œâ”€â”€ task1-hindi-cnn-bilstm.ipynb
â”‚   â”‚   â””â”€â”€ task1-tamil-cnn-bilstm.ipynb
â”‚   â”œâ”€â”€ TASK2
â”‚   â”‚   â”œâ”€â”€ task2-eng-cnn-bilstm.ipynb
â”‚   â”‚   â”œâ”€â”€ task2-hindi-cnn-bilstm.ipynb
â”‚   â”‚   â””â”€â”€ task2-tamil-cnn-bilstm.ipynb
â”‚   â””â”€â”€ TASK3
â”‚       â”œâ”€â”€ task3_eng_lstm_cnn.ipynb
â”‚       â”œâ”€â”€ task3-hindi-cnn-bilstm.ipynb
â”‚       â””â”€â”€ task3_tamil_lstm_cnn.ipynb
â”œâ”€â”€ dataset
â”‚   â”œâ”€â”€ Additional_Data
â”‚   â”‚   â”œâ”€â”€ HASOC_data
â”‚   â”‚   â”œâ”€â”€ Hurtlex
â”‚   â”‚   â””â”€â”€ MACD_data
â”‚   â”œâ”€â”€ structure.txt
â”‚   â””â”€â”€ uli_dataset-main
â”‚       â”œâ”€â”€ LICENSE
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ testing
â”‚       â””â”€â”€ training
â”œâ”€â”€ final_codes
â”‚   â”œâ”€â”€ TASK1
â”‚   â”‚   â”œâ”€â”€ fusion
â”‚   â”‚   â”œâ”€â”€ fusion_hurtlex
â”‚   â”‚   â””â”€â”€ hurtlex
â”‚   â”œâ”€â”€ TASK2
â”‚   â”‚   â”œâ”€â”€ fusion-hurtlex-english-task2.ipynb
â”‚   â”‚   â”œâ”€â”€ fusion-hurtlex-hindi-task2.ipynb
â”‚   â”‚   â””â”€â”€ fusion-task2-tamil.ipynb
â”‚   â””â”€â”€ TASK3
â”‚       â”œâ”€â”€ tamil-fusion-task3.ipynb
â”‚       â”œâ”€â”€ task3-eng-fusion-hurtlex.ipynb
â”‚       â””â”€â”€ task3-hindi-fusion-hurtlex.ipynb
â””â”€â”€ README.md


```