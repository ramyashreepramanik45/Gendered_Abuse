# Gendered Abuse Detection for Indic Languages

This repository contains code and instructions for detecting gendered abuse across Indic languages: Hindi, Tamil, and English. It supports three subtasks as defined in the shared task guidelines.

---

## ğŸ“‚ Baseline_1 Overview

### ğŸ”¹ Subtask 1: Classification using Given Dataset

- Code is located in the `subtask_1/` folder.
- Dataset used: **ULI Dataset (label_1 only)**
- Files are available under `uli_dataset-main/training/` and `uli_dataset-main/testing/`.

#### ğŸ“Š Training Files:
- `train_en_l1.csv`
- `train_hi_l1.csv`
- `train_ta_l1.csv`

#### ğŸ“ˆ Testing Files:
- `test_en_l1.csv`
- `test_hi_l1.csv`
- `test_ta_l1.csv`

> âœï¸ **Note:** Update file paths in the `.ipynb` notebooks to match the dataset structure before running.

---

### ğŸ”¹ Subtask 2: Transfer Learning with External Data

- Uses **external datasets** + **ULI dataset** for fine-tuning.

#### ğŸ—ƒ External Datasets (Located in `Additional_Data/`):
- **MACD Dataset** (Hindi & Tamil):
  - `MACD_data/hindi_data/hindi_train.csv`
  - `MACD_data/hindi_data/hindi_val.csv`
  - `MACD_data/tamil_data/tamil_train.csv`
  - `MACD_data/tamil_data/tamil_val.csv`

- **HASOC Dataset** (English):
  - `HASOC_data/english_dataset.tsv`
  - `hasoc2019_en_test-2919.tsv`

#### ğŸ” Fine-tuning Data (ULI Dataset):
- Use relevant files from `uli_dataset-main/training/` for final training.

> âœï¸ Modify the paths inside the subtask_2 `.ipynb` notebooks before running.

---

### ğŸ”¹ Subtask 3: Multitask Learning

- Multi-label classification using `label_1` and `label_3` from the **ULI Dataset**.

#### ğŸ§¾ Files Used:
- **Training:**
  - `train_en_l1.csv`, `train_en_l3.csv`
  - `train_hi_l1.csv`, `train_hi_l3.csv`
  - `train_ta_l1.csv`, `train_ta_l3.csv`
  
- **Testing:**
  - `test_en_l1.csv`, `test_en_l3.csv`
  - `test_hi_l1.csv`, `test_hi_l3.csv`
  - `test_ta_l1.csv`, `test_ta_l3.csv`

> âœï¸ Ensure to update paths in the `subtask_3/` notebooks to use correct files.

---

## ğŸ“ Dataset Directory Structure

```
â”œâ”€â”€ Additional_Data
â”‚Â Â  â”œâ”€â”€ HASOC_data
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ english_dataset.tsv
â”‚Â Â  â”‚Â Â  â””â”€â”€ hasoc2019_en_test-2919.tsv
â”‚Â Â  â””â”€â”€ MACD_data
â”‚Â Â      â”œâ”€â”€ hindi_data
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ hindi_train.csv
â”‚Â Â      â”‚Â Â  â””â”€â”€ hindi_val.csv
â”‚Â Â      â””â”€â”€ tamil_data
â”‚Â Â          â”œâ”€â”€ tamil_train.csv
â”‚Â Â          â””â”€â”€ tamil_val.csv
â”œâ”€â”€ structure.txt
â””â”€â”€ uli_dataset-main
    â”œâ”€â”€ LICENSE
    â”œâ”€â”€ README.md
    â”œâ”€â”€ testing
    â”‚Â Â  â”œâ”€â”€ test_en_l1.csv
    â”‚Â Â  â”œâ”€â”€ test_en_l2.csv
    â”‚Â Â  â”œâ”€â”€ test_en_l3.csv
    â”‚Â Â  â”œâ”€â”€ test_hi_l1.csv
    â”‚Â Â  â”œâ”€â”€ test_hi_l2.csv
    â”‚Â Â  â”œâ”€â”€ test_hi_l3.csv
    â”‚Â Â  â”œâ”€â”€ test_ta_l1.csv
    â”‚Â Â  â”œâ”€â”€ test_ta_l2.csv
    â”‚Â Â  â””â”€â”€ test_ta_l3.csv
    â””â”€â”€ training
        â”œâ”€â”€ train_en_l1.csv
        â”œâ”€â”€ train_en_l2.csv
        â”œâ”€â”€ train_en_l3.csv
        â”œâ”€â”€ train_hi_l1.csv
        â”œâ”€â”€ train_hi_l2.csv
        â”œâ”€â”€ train_hi_l3.csv
        â”œâ”€â”€ train_ta_l1.csv
        â”œâ”€â”€ train_ta_l2.csv
        â””â”€â”€ train_ta_l3.csv


```